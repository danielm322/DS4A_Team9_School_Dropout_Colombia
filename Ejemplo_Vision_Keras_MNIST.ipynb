{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Keras_MNIST.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/danielm322/DS4A_Team9_Social_Distancing_Detector/blob/master/Ejemplo_Vision_Keras_MNIST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ocNJrYHiZ2_g",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "44d97813-d7ec-49c2-f415-0ed0cb06c2c2"
      },
      "source": [
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from keras.models import Sequential\n",
        "from keras.layers.core import Dense\n",
        "from keras.optimizers import SGD\n",
        "from sklearn import datasets\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mNMFLpTcaSmZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Grabbing the MNIST dataset\n",
        "dataset = datasets.fetch_openml('mnist_784')\n",
        "\n",
        "# Scale raw pixel intensities to [0, 1], then split data\n",
        "data = dataset.data.astype(\"float\") / 255.0\n",
        "(trainX, testX, trainY, testY) = train_test_split(data, dataset.target, test_size=0.25)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XkNuFa7AcjzG",
        "colab_type": "code",
        "outputId": "6c8dd529-cc92-42a5-dd05-74e78d5a24e8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "data.shape"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(70000, 784)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lGP9ttnibKFp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# convert labels from integers to vectors . Se llama One Hot encoding\n",
        "lb = LabelBinarizer()\n",
        "trainY = lb.fit_transform(trainY)\n",
        "testY = lb.fit_transform(testY)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2WdE3OF7cuCx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define the 784-256-128-10 architecture using keras\n",
        "model = Sequential()\n",
        "model.add(Dense(256, input_shape=(784,), activation=\"sigmoid\"))\n",
        "model.add(Dense(128, activation=\"sigmoid\"))\n",
        "model.add(Dense(10, activation=\"softmax\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cbseNw8ldgD6",
        "colab_type": "code",
        "outputId": "ed4b5902-2372-4130-8b40-c7a38d9b4989",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "sgd = SGD(0.01)\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=sgd, metrics=[\"accuracy\"])\n",
        "H = model.fit(trainX, trainY, validation_data=(testX, testY), epochs=100, batch_size=128)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 52500 samples, validate on 17500 samples\n",
            "Epoch 1/100\n",
            "52500/52500 [==============================] - 3s 64us/step - loss: 2.2868 - accuracy: 0.1821 - val_loss: 2.2535 - val_accuracy: 0.2675\n",
            "Epoch 2/100\n",
            "52500/52500 [==============================] - 2s 32us/step - loss: 2.2253 - accuracy: 0.3705 - val_loss: 2.1936 - val_accuracy: 0.5130\n",
            "Epoch 3/100\n",
            "52500/52500 [==============================] - 2s 32us/step - loss: 2.1581 - accuracy: 0.5186 - val_loss: 2.1159 - val_accuracy: 0.5442\n",
            "Epoch 4/100\n",
            "52500/52500 [==============================] - 2s 32us/step - loss: 2.0661 - accuracy: 0.5919 - val_loss: 2.0071 - val_accuracy: 0.5982\n",
            "Epoch 5/100\n",
            "52500/52500 [==============================] - 2s 32us/step - loss: 1.9377 - accuracy: 0.6296 - val_loss: 1.8563 - val_accuracy: 0.6444\n",
            "Epoch 6/100\n",
            "52500/52500 [==============================] - 2s 32us/step - loss: 1.7685 - accuracy: 0.6629 - val_loss: 1.6703 - val_accuracy: 0.6721\n",
            "Epoch 7/100\n",
            "52500/52500 [==============================] - 2s 33us/step - loss: 1.5746 - accuracy: 0.6946 - val_loss: 1.4746 - val_accuracy: 0.6821\n",
            "Epoch 8/100\n",
            "52500/52500 [==============================] - 2s 32us/step - loss: 1.3851 - accuracy: 0.7226 - val_loss: 1.2936 - val_accuracy: 0.7323\n",
            "Epoch 9/100\n",
            "52500/52500 [==============================] - 2s 32us/step - loss: 1.2201 - accuracy: 0.7483 - val_loss: 1.1449 - val_accuracy: 0.7655\n",
            "Epoch 10/100\n",
            "52500/52500 [==============================] - 2s 32us/step - loss: 1.0839 - accuracy: 0.7709 - val_loss: 1.0225 - val_accuracy: 0.7782\n",
            "Epoch 11/100\n",
            "52500/52500 [==============================] - 2s 32us/step - loss: 0.9742 - accuracy: 0.7859 - val_loss: 0.9244 - val_accuracy: 0.7995\n",
            "Epoch 12/100\n",
            "52500/52500 [==============================] - 2s 33us/step - loss: 0.8857 - accuracy: 0.7994 - val_loss: 0.8464 - val_accuracy: 0.8106\n",
            "Epoch 13/100\n",
            "52500/52500 [==============================] - 2s 32us/step - loss: 0.8140 - accuracy: 0.8112 - val_loss: 0.7818 - val_accuracy: 0.8183\n",
            "Epoch 14/100\n",
            "52500/52500 [==============================] - 2s 32us/step - loss: 0.7553 - accuracy: 0.8202 - val_loss: 0.7291 - val_accuracy: 0.8306\n",
            "Epoch 15/100\n",
            "52500/52500 [==============================] - 2s 33us/step - loss: 0.7067 - accuracy: 0.8281 - val_loss: 0.6850 - val_accuracy: 0.8371\n",
            "Epoch 16/100\n",
            "52500/52500 [==============================] - 2s 32us/step - loss: 0.6662 - accuracy: 0.8358 - val_loss: 0.6476 - val_accuracy: 0.8425\n",
            "Epoch 17/100\n",
            "52500/52500 [==============================] - 2s 32us/step - loss: 0.6318 - accuracy: 0.8418 - val_loss: 0.6166 - val_accuracy: 0.8493\n",
            "Epoch 18/100\n",
            "52500/52500 [==============================] - 2s 33us/step - loss: 0.6026 - accuracy: 0.8470 - val_loss: 0.5896 - val_accuracy: 0.8560\n",
            "Epoch 19/100\n",
            "52500/52500 [==============================] - 2s 33us/step - loss: 0.5771 - accuracy: 0.8527 - val_loss: 0.5659 - val_accuracy: 0.8602\n",
            "Epoch 20/100\n",
            "52500/52500 [==============================] - 2s 34us/step - loss: 0.5549 - accuracy: 0.8573 - val_loss: 0.5451 - val_accuracy: 0.8631\n",
            "Epoch 21/100\n",
            "52500/52500 [==============================] - 2s 34us/step - loss: 0.5352 - accuracy: 0.8614 - val_loss: 0.5271 - val_accuracy: 0.8670\n",
            "Epoch 22/100\n",
            "52500/52500 [==============================] - 2s 34us/step - loss: 0.5178 - accuracy: 0.8648 - val_loss: 0.5105 - val_accuracy: 0.8702\n",
            "Epoch 23/100\n",
            "52500/52500 [==============================] - 2s 32us/step - loss: 0.5022 - accuracy: 0.8681 - val_loss: 0.4957 - val_accuracy: 0.8735\n",
            "Epoch 24/100\n",
            "52500/52500 [==============================] - 2s 32us/step - loss: 0.4882 - accuracy: 0.8711 - val_loss: 0.4835 - val_accuracy: 0.8750\n",
            "Epoch 25/100\n",
            "52500/52500 [==============================] - 2s 31us/step - loss: 0.4753 - accuracy: 0.8744 - val_loss: 0.4714 - val_accuracy: 0.8783\n",
            "Epoch 26/100\n",
            "52500/52500 [==============================] - 2s 32us/step - loss: 0.4639 - accuracy: 0.8759 - val_loss: 0.4601 - val_accuracy: 0.8817\n",
            "Epoch 27/100\n",
            "52500/52500 [==============================] - 2s 32us/step - loss: 0.4535 - accuracy: 0.8781 - val_loss: 0.4502 - val_accuracy: 0.8834\n",
            "Epoch 28/100\n",
            "52500/52500 [==============================] - 2s 33us/step - loss: 0.4439 - accuracy: 0.8805 - val_loss: 0.4410 - val_accuracy: 0.8850\n",
            "Epoch 29/100\n",
            "52500/52500 [==============================] - 2s 34us/step - loss: 0.4352 - accuracy: 0.8831 - val_loss: 0.4329 - val_accuracy: 0.8862\n",
            "Epoch 30/100\n",
            "52500/52500 [==============================] - 2s 34us/step - loss: 0.4271 - accuracy: 0.8844 - val_loss: 0.4252 - val_accuracy: 0.8878\n",
            "Epoch 31/100\n",
            "52500/52500 [==============================] - 2s 34us/step - loss: 0.4198 - accuracy: 0.8855 - val_loss: 0.4181 - val_accuracy: 0.8893\n",
            "Epoch 32/100\n",
            "52500/52500 [==============================] - 2s 34us/step - loss: 0.4130 - accuracy: 0.8872 - val_loss: 0.4124 - val_accuracy: 0.8907\n",
            "Epoch 33/100\n",
            "52500/52500 [==============================] - 2s 35us/step - loss: 0.4067 - accuracy: 0.8882 - val_loss: 0.4061 - val_accuracy: 0.8927\n",
            "Epoch 34/100\n",
            "52500/52500 [==============================] - 2s 32us/step - loss: 0.4010 - accuracy: 0.8897 - val_loss: 0.4008 - val_accuracy: 0.8933\n",
            "Epoch 35/100\n",
            "52500/52500 [==============================] - 2s 33us/step - loss: 0.3956 - accuracy: 0.8906 - val_loss: 0.3953 - val_accuracy: 0.8939\n",
            "Epoch 36/100\n",
            "52500/52500 [==============================] - 2s 32us/step - loss: 0.3906 - accuracy: 0.8912 - val_loss: 0.3907 - val_accuracy: 0.8947\n",
            "Epoch 37/100\n",
            "52500/52500 [==============================] - 2s 32us/step - loss: 0.3858 - accuracy: 0.8929 - val_loss: 0.3864 - val_accuracy: 0.8957\n",
            "Epoch 38/100\n",
            "52500/52500 [==============================] - 2s 32us/step - loss: 0.3814 - accuracy: 0.8936 - val_loss: 0.3819 - val_accuracy: 0.8962\n",
            "Epoch 39/100\n",
            "52500/52500 [==============================] - 2s 32us/step - loss: 0.3775 - accuracy: 0.8942 - val_loss: 0.3781 - val_accuracy: 0.8971\n",
            "Epoch 40/100\n",
            "52500/52500 [==============================] - 2s 32us/step - loss: 0.3735 - accuracy: 0.8950 - val_loss: 0.3746 - val_accuracy: 0.8978\n",
            "Epoch 41/100\n",
            "52500/52500 [==============================] - 2s 32us/step - loss: 0.3700 - accuracy: 0.8957 - val_loss: 0.3714 - val_accuracy: 0.8981\n",
            "Epoch 42/100\n",
            "52500/52500 [==============================] - 2s 32us/step - loss: 0.3665 - accuracy: 0.8965 - val_loss: 0.3678 - val_accuracy: 0.8986\n",
            "Epoch 43/100\n",
            "52500/52500 [==============================] - 2s 32us/step - loss: 0.3633 - accuracy: 0.8974 - val_loss: 0.3654 - val_accuracy: 0.8998\n",
            "Epoch 44/100\n",
            "52500/52500 [==============================] - 2s 32us/step - loss: 0.3601 - accuracy: 0.8977 - val_loss: 0.3621 - val_accuracy: 0.9001\n",
            "Epoch 45/100\n",
            "52500/52500 [==============================] - 2s 32us/step - loss: 0.3572 - accuracy: 0.8987 - val_loss: 0.3598 - val_accuracy: 0.9000\n",
            "Epoch 46/100\n",
            "52500/52500 [==============================] - 2s 32us/step - loss: 0.3545 - accuracy: 0.8995 - val_loss: 0.3569 - val_accuracy: 0.9013\n",
            "Epoch 47/100\n",
            "52500/52500 [==============================] - 2s 32us/step - loss: 0.3518 - accuracy: 0.9000 - val_loss: 0.3539 - val_accuracy: 0.9011\n",
            "Epoch 48/100\n",
            "52500/52500 [==============================] - 2s 32us/step - loss: 0.3493 - accuracy: 0.9001 - val_loss: 0.3519 - val_accuracy: 0.9007\n",
            "Epoch 49/100\n",
            "52500/52500 [==============================] - 2s 32us/step - loss: 0.3469 - accuracy: 0.9011 - val_loss: 0.3497 - val_accuracy: 0.9027\n",
            "Epoch 50/100\n",
            "52500/52500 [==============================] - 2s 32us/step - loss: 0.3445 - accuracy: 0.9012 - val_loss: 0.3472 - val_accuracy: 0.9033\n",
            "Epoch 51/100\n",
            "52500/52500 [==============================] - 2s 32us/step - loss: 0.3422 - accuracy: 0.9014 - val_loss: 0.3456 - val_accuracy: 0.9045\n",
            "Epoch 52/100\n",
            "52500/52500 [==============================] - 2s 32us/step - loss: 0.3401 - accuracy: 0.9024 - val_loss: 0.3431 - val_accuracy: 0.9044\n",
            "Epoch 53/100\n",
            "52500/52500 [==============================] - 2s 32us/step - loss: 0.3380 - accuracy: 0.9029 - val_loss: 0.3410 - val_accuracy: 0.9049\n",
            "Epoch 54/100\n",
            "52500/52500 [==============================] - 2s 32us/step - loss: 0.3360 - accuracy: 0.9030 - val_loss: 0.3393 - val_accuracy: 0.9055\n",
            "Epoch 55/100\n",
            "52500/52500 [==============================] - 2s 32us/step - loss: 0.3340 - accuracy: 0.9036 - val_loss: 0.3376 - val_accuracy: 0.9055\n",
            "Epoch 56/100\n",
            "52500/52500 [==============================] - 2s 32us/step - loss: 0.3321 - accuracy: 0.9040 - val_loss: 0.3360 - val_accuracy: 0.9062\n",
            "Epoch 57/100\n",
            "52500/52500 [==============================] - 2s 32us/step - loss: 0.3303 - accuracy: 0.9047 - val_loss: 0.3339 - val_accuracy: 0.9066\n",
            "Epoch 58/100\n",
            "52500/52500 [==============================] - 2s 32us/step - loss: 0.3285 - accuracy: 0.9048 - val_loss: 0.3327 - val_accuracy: 0.9070\n",
            "Epoch 59/100\n",
            "52500/52500 [==============================] - 2s 32us/step - loss: 0.3268 - accuracy: 0.9059 - val_loss: 0.3309 - val_accuracy: 0.9062\n",
            "Epoch 60/100\n",
            "52500/52500 [==============================] - 2s 32us/step - loss: 0.3251 - accuracy: 0.9058 - val_loss: 0.3292 - val_accuracy: 0.9071\n",
            "Epoch 61/100\n",
            "52500/52500 [==============================] - 2s 33us/step - loss: 0.3234 - accuracy: 0.9064 - val_loss: 0.3276 - val_accuracy: 0.9078\n",
            "Epoch 62/100\n",
            "52500/52500 [==============================] - 2s 33us/step - loss: 0.3218 - accuracy: 0.9071 - val_loss: 0.3270 - val_accuracy: 0.9081\n",
            "Epoch 63/100\n",
            "52500/52500 [==============================] - 2s 32us/step - loss: 0.3203 - accuracy: 0.9072 - val_loss: 0.3253 - val_accuracy: 0.9087\n",
            "Epoch 64/100\n",
            "52500/52500 [==============================] - 2s 32us/step - loss: 0.3188 - accuracy: 0.9074 - val_loss: 0.3243 - val_accuracy: 0.9079\n",
            "Epoch 65/100\n",
            "52500/52500 [==============================] - 2s 32us/step - loss: 0.3172 - accuracy: 0.9079 - val_loss: 0.3221 - val_accuracy: 0.9094\n",
            "Epoch 66/100\n",
            "52500/52500 [==============================] - 2s 32us/step - loss: 0.3159 - accuracy: 0.9086 - val_loss: 0.3209 - val_accuracy: 0.9097\n",
            "Epoch 67/100\n",
            "52500/52500 [==============================] - 2s 32us/step - loss: 0.3144 - accuracy: 0.9087 - val_loss: 0.3202 - val_accuracy: 0.9097\n",
            "Epoch 68/100\n",
            "52500/52500 [==============================] - 2s 32us/step - loss: 0.3130 - accuracy: 0.9088 - val_loss: 0.3181 - val_accuracy: 0.9108\n",
            "Epoch 69/100\n",
            "52500/52500 [==============================] - 2s 32us/step - loss: 0.3117 - accuracy: 0.9093 - val_loss: 0.3173 - val_accuracy: 0.9103\n",
            "Epoch 70/100\n",
            "52500/52500 [==============================] - 2s 32us/step - loss: 0.3103 - accuracy: 0.9102 - val_loss: 0.3162 - val_accuracy: 0.9099\n",
            "Epoch 71/100\n",
            "52500/52500 [==============================] - 2s 32us/step - loss: 0.3090 - accuracy: 0.9097 - val_loss: 0.3148 - val_accuracy: 0.9106\n",
            "Epoch 72/100\n",
            "52500/52500 [==============================] - 2s 32us/step - loss: 0.3078 - accuracy: 0.9105 - val_loss: 0.3137 - val_accuracy: 0.9115\n",
            "Epoch 73/100\n",
            "52500/52500 [==============================] - 2s 32us/step - loss: 0.3065 - accuracy: 0.9104 - val_loss: 0.3129 - val_accuracy: 0.9109\n",
            "Epoch 74/100\n",
            "52500/52500 [==============================] - 2s 32us/step - loss: 0.3053 - accuracy: 0.9110 - val_loss: 0.3115 - val_accuracy: 0.9121\n",
            "Epoch 75/100\n",
            "52500/52500 [==============================] - 2s 32us/step - loss: 0.3041 - accuracy: 0.9112 - val_loss: 0.3104 - val_accuracy: 0.9127\n",
            "Epoch 76/100\n",
            "52500/52500 [==============================] - 2s 32us/step - loss: 0.3029 - accuracy: 0.9118 - val_loss: 0.3096 - val_accuracy: 0.9125\n",
            "Epoch 77/100\n",
            "52500/52500 [==============================] - 2s 32us/step - loss: 0.3017 - accuracy: 0.9117 - val_loss: 0.3084 - val_accuracy: 0.9127\n",
            "Epoch 78/100\n",
            "52500/52500 [==============================] - 2s 32us/step - loss: 0.3006 - accuracy: 0.9124 - val_loss: 0.3071 - val_accuracy: 0.9133\n",
            "Epoch 79/100\n",
            "52500/52500 [==============================] - 2s 33us/step - loss: 0.2994 - accuracy: 0.9129 - val_loss: 0.3060 - val_accuracy: 0.9130\n",
            "Epoch 80/100\n",
            "52500/52500 [==============================] - 2s 32us/step - loss: 0.2983 - accuracy: 0.9130 - val_loss: 0.3056 - val_accuracy: 0.9128\n",
            "Epoch 81/100\n",
            "52500/52500 [==============================] - 2s 32us/step - loss: 0.2972 - accuracy: 0.9135 - val_loss: 0.3042 - val_accuracy: 0.9138\n",
            "Epoch 82/100\n",
            "52500/52500 [==============================] - 2s 32us/step - loss: 0.2961 - accuracy: 0.9138 - val_loss: 0.3033 - val_accuracy: 0.9135\n",
            "Epoch 83/100\n",
            "52500/52500 [==============================] - 2s 32us/step - loss: 0.2950 - accuracy: 0.9137 - val_loss: 0.3021 - val_accuracy: 0.9136\n",
            "Epoch 84/100\n",
            "52500/52500 [==============================] - 2s 32us/step - loss: 0.2939 - accuracy: 0.9146 - val_loss: 0.3013 - val_accuracy: 0.9138\n",
            "Epoch 85/100\n",
            "52500/52500 [==============================] - 2s 33us/step - loss: 0.2929 - accuracy: 0.9147 - val_loss: 0.3006 - val_accuracy: 0.9145\n",
            "Epoch 86/100\n",
            "52500/52500 [==============================] - 2s 32us/step - loss: 0.2919 - accuracy: 0.9147 - val_loss: 0.2995 - val_accuracy: 0.9146\n",
            "Epoch 87/100\n",
            "52500/52500 [==============================] - 2s 31us/step - loss: 0.2907 - accuracy: 0.9153 - val_loss: 0.2986 - val_accuracy: 0.9145\n",
            "Epoch 88/100\n",
            "52500/52500 [==============================] - 2s 32us/step - loss: 0.2897 - accuracy: 0.9155 - val_loss: 0.2985 - val_accuracy: 0.9149\n",
            "Epoch 89/100\n",
            "52500/52500 [==============================] - 2s 32us/step - loss: 0.2888 - accuracy: 0.9157 - val_loss: 0.2968 - val_accuracy: 0.9147\n",
            "Epoch 90/100\n",
            "52500/52500 [==============================] - 2s 32us/step - loss: 0.2878 - accuracy: 0.9158 - val_loss: 0.2958 - val_accuracy: 0.9154\n",
            "Epoch 91/100\n",
            "52500/52500 [==============================] - 2s 32us/step - loss: 0.2868 - accuracy: 0.9164 - val_loss: 0.2954 - val_accuracy: 0.9153\n",
            "Epoch 92/100\n",
            "52500/52500 [==============================] - 2s 31us/step - loss: 0.2858 - accuracy: 0.9165 - val_loss: 0.2946 - val_accuracy: 0.9147\n",
            "Epoch 93/100\n",
            "52500/52500 [==============================] - 2s 33us/step - loss: 0.2850 - accuracy: 0.9167 - val_loss: 0.2937 - val_accuracy: 0.9158\n",
            "Epoch 94/100\n",
            "52500/52500 [==============================] - 2s 32us/step - loss: 0.2839 - accuracy: 0.9174 - val_loss: 0.2928 - val_accuracy: 0.9159\n",
            "Epoch 95/100\n",
            "52500/52500 [==============================] - 2s 32us/step - loss: 0.2830 - accuracy: 0.9171 - val_loss: 0.2917 - val_accuracy: 0.9166\n",
            "Epoch 96/100\n",
            "52500/52500 [==============================] - 2s 32us/step - loss: 0.2820 - accuracy: 0.9178 - val_loss: 0.2913 - val_accuracy: 0.9165\n",
            "Epoch 97/100\n",
            "52500/52500 [==============================] - 2s 32us/step - loss: 0.2812 - accuracy: 0.9181 - val_loss: 0.2901 - val_accuracy: 0.9169\n",
            "Epoch 98/100\n",
            "52500/52500 [==============================] - 2s 32us/step - loss: 0.2802 - accuracy: 0.9182 - val_loss: 0.2896 - val_accuracy: 0.9164\n",
            "Epoch 99/100\n",
            "52500/52500 [==============================] - 2s 32us/step - loss: 0.2793 - accuracy: 0.9183 - val_loss: 0.2888 - val_accuracy: 0.9175\n",
            "Epoch 100/100\n",
            "52500/52500 [==============================] - 2s 32us/step - loss: 0.2784 - accuracy: 0.9186 - val_loss: 0.2880 - val_accuracy: 0.9173\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NfGP35LUeG_J",
        "colab_type": "code",
        "outputId": "8cba39f3-3806-44c8-c82b-18a89d40fdd3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "source": [
        "# evaluate the network\n",
        "predictions = model.predict(testX, batch_size=128)\n",
        "print(classification_report(testY.argmax(axis=1), predictions.argmax(axis=1), target_names=[str(x) for x in lb.classes_]))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.97      0.96      1716\n",
            "           1       0.94      0.96      0.95      2013\n",
            "           2       0.91      0.90      0.90      1664\n",
            "           3       0.92      0.89      0.90      1835\n",
            "           4       0.91      0.93      0.92      1746\n",
            "           5       0.88      0.88      0.88      1602\n",
            "           6       0.93      0.95      0.94      1667\n",
            "           7       0.93      0.93      0.93      1817\n",
            "           8       0.90      0.86      0.88      1693\n",
            "           9       0.90      0.89      0.90      1747\n",
            "\n",
            "    accuracy                           0.92     17500\n",
            "   macro avg       0.92      0.92      0.92     17500\n",
            "weighted avg       0.92      0.92      0.92     17500\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dCWRK0tsfV1v",
        "colab_type": "code",
        "outputId": "4f4c4d98-3558-4c59-e474-115dd1af8d5b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        }
      },
      "source": [
        "plt.style.use(\"ggplot\")\n",
        "plt.figure()\n",
        "plt.plot(np.arange(0, 100), H.history[\"loss\"], label=\"train_loss\")\n",
        "plt.plot(np.arange(0, 100), H.history[\"val_loss\"], label=\"val_loss\")\n",
        "plt.plot(np.arange(0, 100), H.history[\"acc\"], label=\"train_acc\")\n",
        "plt.plot(np.arange(0, 100), H.history[\"val_acc\"], label=\"val_acc\")\n",
        "plt.legend()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f21c0311748>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/wHJR/Ihz3b03QAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LGe4TJ85fyCM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# The closeness of the lines implies that there is no overfitting occurring"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}